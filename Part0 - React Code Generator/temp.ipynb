{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file 'output.json' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define the root directory where folders are located\n",
    "root_directory = \"elements\"  # Change this to your actual root directory\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Iterate through each folder in the root directory\n",
    "for folder_name in os.listdir(root_directory):\n",
    "    folder_path = os.path.join(root_directory, folder_name)\n",
    "    \n",
    "    if os.path.isdir(folder_path):\n",
    "        code_content = None\n",
    "        index_content = None\n",
    "        description_content = None\n",
    "        \n",
    "        # Read Code.tsx file\n",
    "        code_file_path = os.path.join(folder_path, \"Code.tsx\")\n",
    "        if os.path.exists(code_file_path):\n",
    "            with open(code_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                code_content = file.read()\n",
    "        \n",
    "        # Read index.txt file\n",
    "        index_file_path = os.path.join(folder_path, \"index.txt\")\n",
    "        if os.path.exists(index_file_path):\n",
    "            with open(index_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                index_content = file.read()\n",
    "\n",
    "        # Read description.txt file\n",
    "        description_file_path = os.path.join(folder_path, \"description.txt\")\n",
    "        if os.path.exists(description_file_path):\n",
    "            with open(description_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                description_content = file.read()\n",
    "        \n",
    "        # Append result to the list\n",
    "        results.append({\n",
    "            \"elementType\": folder_name,\n",
    "            \"code\": code_content,\n",
    "            \"meta\": index_content,\n",
    "            \"description\": description_content\n",
    "        })\n",
    "\n",
    "# Save results to a JSON file\n",
    "output_file = \"output.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(results, json_file, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"JSON file '{output_file}' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "import langchain\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import LanceDB\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from typing import List, Dict\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Iranian\\AppData\\Local\\Temp\\ipykernel_3388\\562937975.py:22: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  ollama_model = ChatOllama(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, Optional\n",
    "from langchain.chat_models import ChatOllama\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s - %(message)s\", level=logging.INFO)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model= \"gpt-4o\",\n",
    "    api_key= os.environ[\"GITHUB_API_KEY\"],\n",
    "    base_url= \"https://models.inference.ai.azure.com\",\n",
    ")\n",
    "\n",
    "TOGETHER_AI_BASE_URL = \"https://api.together.xyz/v1\"\n",
    "llama3_3_chat = ChatOpenAI(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
    "    base_url=TOGETHER_AI_BASE_URL,\n",
    "    api_key=os.environ[\"TOGETHERAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "ollama_model = ChatOllama(\n",
    "    model=\"llama3.2:latest\", \n",
    "    base_url=\"http://localhost:11434\" \n",
    ")\n",
    "\n",
    "class StateDefinition(BaseModel):\n",
    "    name: str = Field(..., title=\"State Name\")\n",
    "    defaultValue: str = Field(..., title=\"Default Value\")\n",
    "    type: Literal[\"STRING\", \"NUMBER\", \"BOOLEAN\", \"OBJECT\", \"ARRAY\"] = Field(..., title=\"Type of State\")\n",
    "\n",
    "class PropDefinition(BaseModel):\n",
    "    name: str = Field(..., title=\"Prop Name\")\n",
    "    type: Literal[\"STRING\", \"NUMBER\", \"BOOLEAN\", \"OBJECT\", \"ARRAY\", \"FUNCTION\"] = Field(..., title=\"Type of Prop\")\n",
    "\n",
    "class FunctionDefinition(BaseModel):\n",
    "    name: str = Field(..., title=\"Function Name\")\n",
    "    inputParams: List[str] = Field(..., title=\"Input Parameters of Function\")\n",
    "    code: str = Field(..., title=\"Function code\")\n",
    "\n",
    "class ComponentDefinition(BaseModel):\n",
    "    title: str = Field(\"\", title=\"Component Title\")\n",
    "    description: str = Field(\"\", title=\"Component Description\")\n",
    "    states: List[StateDefinition] = Field([], title=\"States used in Component\")\n",
    "    props: List[PropDefinition] = Field([], title=\"Props used in Component\")\n",
    "    functions: List[FunctionDefinition] = Field([], title=\"Functions used in Component\")\n",
    "    jsx_code: str = Field(\"\", title=\"jsx code of Component\")\n",
    "    component_code: str = Field(\"\", title=\"code of Component\")\n",
    "    elementTypes: List[str] = Field([], title=\"Element Types used in Component\")\n",
    "\n",
    "class TaskDefinition(BaseModel):\n",
    "    title: str = Field(..., title=\"Task Title\")\n",
    "    result_task: ComponentDefinition = Field(None, title=\"Result Task\")\n",
    "\n",
    "# Define Agent State\n",
    "class AgentState(BaseModel):\n",
    "    query: str\n",
    "    is_relevant: bool = True\n",
    "    tasks: List[TaskDefinition] = []\n",
    "    final_result: ComponentDefinition = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to use the Gemma, you will need to authenticate with HuggingFace, Skip this step, if you have the model already downloaded\n",
    "# from huggingface_hub import login\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:31:51,496 - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62d868b7bae4057a2a059d181783696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468a34e29a954635bcc7049cb51101a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lancedb.embeddings import get_registry\n",
    "embedding_model = get_registry().get(\"sentence-transformers\").create(name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "#You should put HF_TOKEN in the Notebook enviroment variables\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "\n",
    "# Connect to LanceDB (Vector Database for JSX Retrieval)\n",
    "db = lancedb.connect(\".lancedb\")  \n",
    "# vector_store = LanceDB(db, OpenAIEmbeddings())\n",
    "\n",
    "data = []\n",
    "# read data from output.json file\n",
    "with open(\"output.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "class ChunksOfData(LanceModel):\n",
    "    elementType: str = \"\"\n",
    "    code: str | None = None  # Allow null values\n",
    "    meta: str = \"\"\n",
    "    description: str = embedding_model.SourceField()\n",
    "    vector: Vector(embedding_model.ndims()) = embedding_model.VectorField()\n",
    "\n",
    "\n",
    "tbl = db.create_table(\n",
    "    \"react_elements\",\n",
    "    data= data,\n",
    "    schema=ChunksOfData,\n",
    "    exist_ok=True,\n",
    "    mode=\"overwrite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fd92981dfe40fc9361b133a7730e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elementType</th>\n",
       "      <th>code</th>\n",
       "      <th>meta</th>\n",
       "      <th>description</th>\n",
       "      <th>vector</th>\n",
       "      <th>_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STEPER_CONTAINER</td>\n",
       "      <td>import React, { HTMLAttributes, useEffect } fr...</td>\n",
       "      <td>{\\n  elementType: \"KdStepRoot\",\\n  children: [...</td>\n",
       "      <td>The StepperContainer component is a customizab...</td>\n",
       "      <td>[-0.081205554, -0.016815962, 0.015941583, 0.08...</td>\n",
       "      <td>0.498129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STEPER_ELEMENT</td>\n",
       "      <td>import React from \"react\";\\nimport Stepper, { ...</td>\n",
       "      <td>{\\n  elementType: \"KdStepContent\",\\n  children...</td>\n",
       "      <td>The StepperElement component is a customizable...</td>\n",
       "      <td>[-0.07910837, -0.005119668, 0.024634406, 0.075...</td>\n",
       "      <td>0.522580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DIVIDER</td>\n",
       "      <td>import { Divider, DividerProps } from \"@mui/ma...</td>\n",
       "      <td>{\\n  elementType: \"KdpaDivider\",\\n  children: ...</td>\n",
       "      <td>The Divider component is a customizable divide...</td>\n",
       "      <td>[-0.05971071, 0.013275463, 0.042954285, 0.0310...</td>\n",
       "      <td>0.838013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAYOUT_ROW</td>\n",
       "      <td>import React from \"react\";\\nimport Grid, { Gri...</td>\n",
       "      <td>{\\n  elementType: \"KdpaGrid\",\\n  children: [],...</td>\n",
       "      <td>The LayoutRow component is a simple customizab...</td>\n",
       "      <td>[-0.043467417, -0.0008123551, 0.049763795, -0....</td>\n",
       "      <td>0.871431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TAB_CONTAINER</td>\n",
       "      <td>import * as Tabs from \"@radix-ui/react-tabs\";\\...</td>\n",
       "      <td>{\\n  elementType: \"KdTabsRoot\",\\n  children: [...</td>\n",
       "      <td>The TabConatiner component is a customizable t...</td>\n",
       "      <td>[-0.031779632, 0.052633706, 0.0034408066, 0.05...</td>\n",
       "      <td>0.908668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        elementType                                               code  \\\n",
       "0  STEPER_CONTAINER  import React, { HTMLAttributes, useEffect } fr...   \n",
       "1    STEPER_ELEMENT  import React from \"react\";\\nimport Stepper, { ...   \n",
       "2           DIVIDER  import { Divider, DividerProps } from \"@mui/ma...   \n",
       "3        LAYOUT_ROW  import React from \"react\";\\nimport Grid, { Gri...   \n",
       "4     TAB_CONTAINER  import * as Tabs from \"@radix-ui/react-tabs\";\\...   \n",
       "\n",
       "                                                meta  \\\n",
       "0  {\\n  elementType: \"KdStepRoot\",\\n  children: [...   \n",
       "1  {\\n  elementType: \"KdStepContent\",\\n  children...   \n",
       "2  {\\n  elementType: \"KdpaDivider\",\\n  children: ...   \n",
       "3  {\\n  elementType: \"KdpaGrid\",\\n  children: [],...   \n",
       "4  {\\n  elementType: \"KdTabsRoot\",\\n  children: [...   \n",
       "\n",
       "                                         description  \\\n",
       "0  The StepperContainer component is a customizab...   \n",
       "1  The StepperElement component is a customizable...   \n",
       "2  The Divider component is a customizable divide...   \n",
       "3  The LayoutRow component is a simple customizab...   \n",
       "4  The TabConatiner component is a customizable t...   \n",
       "\n",
       "                                              vector  _distance  \n",
       "0  [-0.081205554, -0.016815962, 0.015941583, 0.08...   0.498129  \n",
       "1  [-0.07910837, -0.005119668, 0.024634406, 0.075...   0.522580  \n",
       "2  [-0.05971071, 0.013275463, 0.042954285, 0.0310...   0.838013  \n",
       "3  [-0.043467417, -0.0008123551, 0.049763795, -0....   0.871431  \n",
       "4  [-0.031779632, 0.052633706, 0.0034408066, 0.05...   0.908668  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl = db.open_table(\"react_elements\")\n",
    "query = \"stepper\"\n",
    "\n",
    "res= tbl.search(query).limit(5).to_pandas()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class RelevantUserQuery(BaseModel):\n",
    "    is_relevant : bool = Field(description=\"boolean for relevance or not\")\n",
    "\n",
    "# **Relevance Check Node**\n",
    "def check_relevance(state: AgentState):\n",
    "    prompt = f\"Is the following request related to front-end UI component generation? \\n\\nQuery: {state.query}\"\n",
    "    \n",
    "    structured_model = llm.with_structured_output(RelevantUserQuery)\n",
    "    \n",
    "    response = structured_model.invoke([SystemMessage(content=\"You determine if a query is relevant to UI development.\"),\n",
    "                           HumanMessage(content=prompt)])\n",
    "        \n",
    "    logging.info(f\"Relevance Check Response: {response.is_relevant}\")\n",
    "    \n",
    "    state.is_relevant = response.is_relevant\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class TaskList(BaseModel):\n",
    "    tasks : List[str] = Field(description=\"list of tasks\")\n",
    "\n",
    "# **Task Processing Node**\n",
    "def process_query(state: AgentState):\n",
    "    prompt = f\"{state.query}\"\n",
    "\n",
    "    structured_model = llm.with_structured_output(TaskList)\n",
    "    response = structured_model.invoke([SystemMessage(content=\"\"\"You analyze UI queries and generate structured tasks.\n",
    "                                                      you are assistant for craete react component code but in mullti step process.\n",
    "                                                      you should generate each of tag element with style and attributes recursively.\n",
    "\n",
    "                                                      for done this recursively you should the user query divide to some task and do it step by step.\n",
    "                                                      now create sub task of user query for generate component code for each tag element recursively.\n",
    "                                                      \"\"\"),\n",
    "                           HumanMessage(content=prompt)])\n",
    "    \n",
    "    logging.info(f\"Task Processing Response: {response.tasks}\\n ======================================= \\n\")\n",
    "    state.tasks = [ {\"title\": task } for task in response.tasks]\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, ValidationError\n",
    "\n",
    "class JsxTask(BaseModel):\n",
    "    jsx : str = Field(description=\" string of jsx code\")\n",
    "    elementTypes : List[str] = Field(description=\"list of element types required in the jsx code\")\n",
    "\n",
    "# **Generate JSX Using LLM**\n",
    "def generate_code(state: AgentState):\n",
    "    for task in state.tasks:\n",
    "        context = ''.join([f\"elementType({c['elementType']}): {c['description']}\\n\\n\" for c in data])\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        Task: {task.title}\\n\\n Context: {context}\\n\\n\n",
    "        \"\"\"\n",
    "        structured_model = llm.with_structured_output(ComponentDefinition)\n",
    "        \n",
    "        response = structured_model.invoke([SystemMessage(content=\"\"\" you are great developer and you can create react component code.\n",
    "                                                          You refine component react to match UI tasks. and list of element types used in JSX code\n",
    "                                                          but my element is specific and you can not use any element.\n",
    "                                                          in context exist my element with description and valid attribute, static attrs and dynamic attrs.\n",
    "                                                          static attrs is fixed and dynamic attrs can be used from state or props or static or ... .\n",
    "                                                          now you should generate jsx code for this task with element types.\n",
    "                                                          \"\"\"),\n",
    "                               HumanMessage(content=prompt)])\n",
    "        \n",
    "        try:\n",
    "            logging.info(\"Generated component react for task '{}': \\n{}\".format(task.title, response))\n",
    "            component = ComponentDefinition(**response.model_dump())\n",
    "            newTask = TaskDefinition(title=task.title, result_task=component)\n",
    "            state.tasks[state.tasks.index(task)] = newTask\n",
    "        except ValidationError as exc:\n",
    "            print(repr(exc.errors()[0]['type']))\n",
    "            #> 'missing'\n",
    "        \n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalResult(BaseModel):\n",
    "    jsx : str = Field(description=\"string of jsx code\")\n",
    "    stateDefinitionList: List[StateDefinition] = Field(description=\"list of state definition\")\n",
    "\n",
    "# **Merge All JSX into a Final Component**\n",
    "def merge_code(state: AgentState):\n",
    "    context = ''.join([f\"{c['elementType']}: {c['description']}\\n\\n\" for c in data])\n",
    "\n",
    "    tasksData = [{\"title\":task.title, \"code\":task.result_task.component_code} for task in state.tasks]\n",
    "\n",
    "    prompt = f\"\"\"the user query is: {state.query}.\\n\\n \n",
    "    at the first we break the user query to sub tasks and recusive generate component code for each of them, this is of sub task and\n",
    "    \n",
    "    generated sub tasks: {tasksData}.\n",
    "    context: {context}.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    structured_model = llm.with_structured_output(ComponentDefinition)\n",
    "    response = structured_model.invoke([SystemMessage(content=\"\"\"You are great developer and you can create react component code.\n",
    "                                                      There was one query and divide that to some tasks and component react for each of them.\n",
    "                                                      You should only use this sub task and component data and combine that for answer the main query.\n",
    "                                                      but my element is specific and you can not use any element.\n",
    "                                                          in context exist my element with description and valid attribute, static attrs and dynamic attrs.\n",
    "                                                          static attrs is fixed and dynamic attrs can be used from state or props or static or ... .\n",
    "                                                      \"\"\"),\n",
    "                           HumanMessage(content=prompt)])\n",
    "\n",
    "    state.final_result = ComponentDefinition(**response.model_dump())\n",
    "    \n",
    "    logging.info(\"Final Generated React components :\\n {}\".format(response))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def decide_mood(state) -> Literal[\"process_query\", END]:\n",
    "    # Often, we will use state to decide on the next node to visit\n",
    "    if state.is_relevant == True:\n",
    "        return \"process_query\"\n",
    "    \n",
    "    else:\n",
    "        return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Define Graph Workflow**\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add Nodes\n",
    "workflow.add_node(\"check_relevance\", check_relevance)\n",
    "workflow.add_node(\"process_query\", process_query)\n",
    "workflow.add_node(\"generate_code\", generate_code)\n",
    "workflow.add_node(\"merge_code\", merge_code)\n",
    "\n",
    "workflow.add_edge(START, \"check_relevance\")\n",
    "\n",
    "# **Conditional Edge:**\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_relevance\",  # From\n",
    "    decide_mood\n",
    ")\n",
    "\n",
    "# Normal Edges\n",
    "workflow.add_edge(\"process_query\", \"generate_code\")\n",
    "workflow.add_edge(\"generate_code\", \"merge_code\")\n",
    "workflow.add_edge(\"merge_code\", END)\n",
    "\n",
    "# Compile and Run\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:32:19,440 - HTTP Request: POST https://models.inference.ai.azure.com/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-02-21 16:32:19,442 - Retrying request to /chat/completions in 0.494438 seconds\n",
      "2025-02-21 16:32:20,525 - HTTP Request: POST https://models.inference.ai.azure.com/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-02-21 16:32:20,527 - Retrying request to /chat/completions in 0.997450 seconds\n",
      "2025-02-21 16:32:22,147 - HTTP Request: POST https://models.inference.ai.azure.com/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 83851 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 83851 seconds before retrying.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m initial_stateee \u001b[38;5;241m=\u001b[39m AgentState(query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mI want a beautifuly header:\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124m                             in the right a image box have logo and title of website.\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m                             in the left many item link that each of them have a icon and text.\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m                             like : link to shoppage, link to about us page, link to contact us page.\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124m                             and at the end of left side a button for login.\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m                             \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_stateee\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1940\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   1938\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1939\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1940\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   1941\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1942\u001b[0m     config,\n\u001b[0;32m   1943\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[0;32m   1944\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   1945\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   1946\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   1947\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   1948\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1949\u001b[0m ):\n\u001b[0;32m   1950\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1951\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1660\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1660\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1661\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1662\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   1663\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   1664\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   1665\u001b[0m         ):\n\u001b[0;32m   1666\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1667\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   1668\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langgraph\\pregel\\runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langgraph\\utils\\runnable.py:408\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    405\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    406\u001b[0m )\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langgraph\\utils\\runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m, in \u001b[0;36mcheck_relevance\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      8\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIs the following request related to front-end UI component generation? \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuery: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;241m.\u001b[39mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m structured_model \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mwith_structured_output(RelevantUserQuery)\n\u001b[1;32m---> 12\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSystemMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou determine if a query is relevant to UI development.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRelevance Check Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mis_relevant\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m state\u001b[38;5;241m.\u001b[39mis_relevant \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mis_relevant\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:3020\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3018\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m   3019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3020\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3021\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3022\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:5352\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5347\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5348\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   5349\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5350\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5351\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5353\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5355\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5356\u001b[0m     )\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    285\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 286\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    287\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    288\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    289\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    290\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    291\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    292\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    293\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    294\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    295\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    647\u001b[0m ]\n\u001b[0;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 633\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    634\u001b[0m                 m,\n\u001b[0;32m    635\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    636\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    637\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    638\u001b[0m             )\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    852\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    853\u001b[0m         )\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:717\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    715\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\openai\\resources\\chat\\completions.py:859\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    856\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    857\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    858\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\openai\\_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1279\u001b[0m     )\n\u001b[1;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\openai\\_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\openai\\_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1045\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1046\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\openai\\_base_client.py:1095\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\openai\\_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1045\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1046\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\openai\\_base_client.py:1095\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\openai\\_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1070\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 83851 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 83851 seconds before retrying.'}}"
     ]
    }
   ],
   "source": [
    "initial_stateee = AgentState(query=\"\"\"I want a beautifuly header:\n",
    "                             in the right a image box have logo and title of website.\n",
    "                             in the left many item link that each of them have a icon and text.\n",
    "                             like : link to shoppage, link to about us page, link to contact us page.\n",
    "                             and at the end of left side a button for login.\n",
    "                             \"\"\")\n",
    "\n",
    "res = graph.invoke(initial_stateee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_state = AgentState(**res)\n",
    "\n",
    "with open(\"agent_state.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(agent_state.model_dump_json(indent=4))\n",
    "\n",
    "with open(\"Component.jsx\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(agent_state.final_result.component_code)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
