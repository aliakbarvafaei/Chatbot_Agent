{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "i:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import lancedb\n",
    "import langchain\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import LanceDB\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from typing import List, Dict\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s - %(message)s\", level=logging.INFO)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model= \"gpt-4o-mini\",\n",
    "    api_key= os.environ[\"GITHUB_API_KEY\"],\n",
    "    base_url= \"https://models.inference.ai.azure.com\",\n",
    ")\n",
    "\n",
    "TOGETHER_AI_BASE_URL = \"https://api.together.xyz/v1\"\n",
    "llama3_3_chat = ChatOpenAI(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
    "    base_url=TOGETHER_AI_BASE_URL,\n",
    "    api_key=os.environ[\"TOGETHERAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "class StateDefinition(BaseModel):\n",
    "    name: str = Field(..., title=\"State Name\")\n",
    "    defaultValue: str = Field(..., title=\"Default Value\")\n",
    "\n",
    "# Define Agent State\n",
    "class AgentState(BaseModel):\n",
    "    query: str\n",
    "    is_relevant: bool = True\n",
    "    tasks: List[str] = []\n",
    "    retrieved_jsx: Dict[str, str] = {}\n",
    "    generated_code: Dict[str, str] = {}\n",
    "    stateList: List[StateDefinition] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 16:41:46,676 - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 27.78it/s]\n"
     ]
    }
   ],
   "source": [
    "from lancedb.embeddings import get_registry\n",
    "embedding_model = get_registry().get(\"sentence-transformers\").create(name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "#You should put HF_TOKEN in the Notebook enviroment variables\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "\n",
    "# Connect to LanceDB (Vector Database for JSX Retrieval)\n",
    "db = lancedb.connect(\".lancedb\")  \n",
    "# vector_store = LanceDB(db, OpenAIEmbeddings())\n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"elementType\":\"div\",\n",
    "        \"jsx\": '<div>hello world</div>',\n",
    "    },\n",
    "    {\n",
    "        \"elementType\":\"span\",\n",
    "        \"jsx\": '<span>hello world</span>',\n",
    "    },\n",
    "    {\n",
    "        \"elementType\":\"a\",\n",
    "        \"jsx\": '<a>hello world</a>',\n",
    "    }\n",
    "]\n",
    "\n",
    "class ChunksOfData(LanceModel):\n",
    "    elementType: str = embedding_model.SourceField()\n",
    "    jsx: str\n",
    "    vector: Vector(embedding_model.ndims()) = embedding_model.VectorField()\n",
    "\n",
    "tbl = db.create_table(\n",
    "    \"react_elements\",\n",
    "    data= data,\n",
    "    schema=ChunksOfData,\n",
    "    exist_ok=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elementType</th>\n",
       "      <th>jsx</th>\n",
       "      <th>vector</th>\n",
       "      <th>_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>div</td>\n",
       "      <td>&lt;div&gt;hello world&lt;/div&gt;</td>\n",
       "      <td>[-0.027646223, -0.043133184, 0.033710644, -0.0...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  elementType                     jsx  \\\n",
       "0         div  <div>hello world</div>   \n",
       "\n",
       "                                              vector  _distance  \n",
       "0  [-0.027646223, -0.043133184, 0.033710644, -0.0...        0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl = db.open_table(\"react_elements\")\n",
    "query = \"div\"\n",
    "\n",
    "res= tbl.search(query).limit(1).to_pandas()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class RelevantUserQuery(BaseModel):\n",
    "    is_relevant : bool = Field(description=\"boolean for relevance or not\")\n",
    "\n",
    "# **Relevance Check Node**\n",
    "def check_relevance(state: AgentState):\n",
    "    prompt = f\"Is the following request related to front-end UI component generation? \\n\\nQuery: {state.query}\"\n",
    "    \n",
    "    structured_model = llm.with_structured_output(RelevantUserQuery)\n",
    "    \n",
    "    response = structured_model.invoke([SystemMessage(content=\"You determine if a query is relevant to UI development.\"),\n",
    "                           HumanMessage(content=prompt)])\n",
    "        \n",
    "    logging.info(f\"Relevance Check Response: {response.is_relevant}\")\n",
    "    \n",
    "    state.is_relevant = response.is_relevant\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class TaskList(BaseModel):\n",
    "    tasks : List[str] = Field(description=\"list of tasks\")\n",
    "\n",
    "# **Task Processing Node**\n",
    "def process_query(state: AgentState):\n",
    "    prompt = f\"{state.query}\"\n",
    "\n",
    "    structured_model = llm.with_structured_output(TaskList)\n",
    "    response = structured_model.invoke([SystemMessage(content=\"\"\"You analyze UI queries and generate structured tasks.\n",
    "                                                      you are assistant for craete jsx code but in mullti step process.\n",
    "                                                      you should generate each of tag element with style and attributes recursively.\n",
    "\n",
    "                                                      for done this recursively you should the user query divide to some task and do it step by step.\n",
    "                                                      now create sub task of user query for generate jsx code for each tag element recursively.\n",
    "                                                      \"\"\"),\n",
    "                           HumanMessage(content=prompt)])\n",
    "    \n",
    "    logging.info(f\"Task Processing Response: {response.tasks}\\n ======================================= \\n\")\n",
    "    state.tasks = response.tasks  # Convert response to a list\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Retrieve JSX from LanceDB**\n",
    "def retrieve_jsx(state: AgentState):\n",
    "    for task in state.tasks:\n",
    "        results = tbl.search(task).limit(1).to_list()\n",
    "\n",
    "        logging.info(f\"Retrieved JSX for task '{task}': {results[0]['jsx'] if results else 'None'}\")\n",
    "        state.retrieved_jsx[task] = results[0][\"jsx\"] if results else \"<div></div>\"\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class JsxTask(BaseModel):\n",
    "    jsx : str = Field(description=\"jsx code\")\n",
    "\n",
    "# **Generate JSX Using LLM**\n",
    "def generate_code(state: AgentState):\n",
    "    for task, retrieved_jsx in state.retrieved_jsx.items():\n",
    "        prompt = f\"\"\"Modify the following JSX to match this task requirement:\\n\\n\n",
    "        Task: {task}\\n\\nRetrieved JSX:\\n{retrieved_jsx}\\n\\n\n",
    "        Ensure minimal and structured JSX.\n",
    "        \"\"\"\n",
    "        structured_model = llm.with_structured_output(JsxTask)\n",
    "        \n",
    "        response = structured_model.invoke([SystemMessage(content=\"You refine JSX to match UI tasks.\"),\n",
    "                               HumanMessage(content=prompt)])\n",
    "        \n",
    "        logging.info(\"Generated JSX for task '{}': {}\".format(task, response.jsx))\n",
    "        state.generated_code[task] = response.jsx\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalResult(BaseModel):\n",
    "    jsx : str = Field(description=\"only jsx code return here,not react component\")\n",
    "    stateDefinitionList: List[StateDefinition] = Field(description=\"list of state definition\")\n",
    "\n",
    "# **Merge All JSX into a Final Component**\n",
    "def merge_code(state: AgentState):\n",
    "    # elements = \"\\n\".join(state.generated_code.values())\n",
    "    prompt = f\"\"\"the user query is: {state.query}.\\n\\n \n",
    "    at the first we break the user query to sub tasks and recusive generate jsx code for each of them, this is of sub task and\n",
    "    generataed jsx: {state.generated_code}.\n",
    "    now i want base on sub generated code and task, you generate complete jsx of user query.\n",
    "    note: response that you generate must be only based on sub generated code and task.\n",
    "    if this jsx need to define state you should define it in stateList. and can be used in jsx code\n",
    "    \"\"\"\n",
    "    \n",
    "    structured_model = llm.with_structured_output(FinalResult)\n",
    "    response = structured_model.invoke([SystemMessage(content=\"You combine JSX elements into a structured jsx.\"),\n",
    "                           HumanMessage(content=prompt)])\n",
    "    state.stateList = state.stateList + (response.stateDefinitionList if response.stateDefinitionList else [])\n",
    "    \n",
    "    logging.info(\"Final Generated React jsx : {}\".format(response.jsx))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def decide_mood(state) -> Literal[\"process_query\", END]:\n",
    "    # Often, we will use state to decide on the next node to visit\n",
    "    if state.is_relevant == True:\n",
    "        return \"process_query\"\n",
    "    \n",
    "    else:\n",
    "        return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Define Graph Workflow**\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add Nodes\n",
    "workflow.add_node(\"check_relevance\", check_relevance)\n",
    "workflow.add_node(\"process_query\", process_query)\n",
    "workflow.add_node(\"retrieve_jsx\", retrieve_jsx)\n",
    "workflow.add_node(\"generate_code\", generate_code)\n",
    "workflow.add_node(\"merge_code\", merge_code)\n",
    "\n",
    "workflow.add_edge(START, \"check_relevance\")\n",
    "\n",
    "# **Conditional Edge:**\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_relevance\",  # From\n",
    "    decide_mood\n",
    ")\n",
    "\n",
    "# Normal Edges\n",
    "workflow.add_edge(\"process_query\", \"retrieve_jsx\")\n",
    "workflow.add_edge(\"retrieve_jsx\", \"generate_code\")\n",
    "workflow.add_edge(\"generate_code\", \"merge_code\")\n",
    "workflow.add_edge(\"merge_code\", END)\n",
    "\n",
    "# Compile and Run\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 16:42:04,334 - HTTP Request: POST https://models.inference.ai.azure.com/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-02-07 16:42:04,340 - Retrying request to /chat/completions in 0.419063 seconds\n",
      "2025-02-07 16:42:05,026 - HTTP Request: POST https://models.inference.ai.azure.com/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-02-07 16:42:05,028 - Retrying request to /chat/completions in 0.985774 seconds\n",
      "2025-02-07 16:42:06,280 - HTTP Request: POST https://models.inference.ai.azure.com/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 150 per 86400s exceeded for UserByModelByDay. Please wait 70911 seconds before retrying.', 'details': 'Rate limit of 150 per 86400s exceeded for UserByModelByDay. Please wait 70911 seconds before retrying.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m initial_stateee \u001b[38;5;241m=\u001b[39m AgentState(query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI want one stepper ui by two step, in step one exist input and checkbox fot name and sex of user and in step two there are many input for address ,age and phone number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_stateee\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1940\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   1938\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1939\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1940\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   1941\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1942\u001b[0m     config,\n\u001b[0;32m   1943\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[0;32m   1944\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   1945\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   1946\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   1947\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   1948\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1949\u001b[0m ):\n\u001b[0;32m   1950\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1951\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1660\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1660\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1661\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1662\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   1663\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   1664\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   1665\u001b[0m         ):\n\u001b[0;32m   1666\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1667\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   1668\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langgraph\\pregel\\runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langgraph\\utils\\runnable.py:408\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    405\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    406\u001b[0m )\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langgraph\\utils\\runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m, in \u001b[0;36mcheck_relevance\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      8\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIs the following request related to front-end UI component generation? \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuery: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;241m.\u001b[39mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m structured_model \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mwith_structured_output(RelevantUserQuery)\n\u001b[1;32m---> 12\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSystemMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou determine if a query is relevant to UI development.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRelevance Check Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mis_relevant\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m state\u001b[38;5;241m.\u001b[39mis_relevant \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mis_relevant\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:3020\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3018\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m   3019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3020\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3021\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3022\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:5352\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5347\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5348\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   5349\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5350\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5351\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5353\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5355\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5356\u001b[0m     )\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    285\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 286\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    287\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    288\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    289\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    290\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    291\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    292\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    293\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    294\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    295\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    647\u001b[0m ]\n\u001b[0;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 633\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    634\u001b[0m                 m,\n\u001b[0;32m    635\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    636\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    637\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    638\u001b[0m             )\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    852\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    853\u001b[0m         )\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:717\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    715\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\openai\\resources\\chat\\completions.py:859\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    856\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    857\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    858\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\openai\\_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1279\u001b[0m     )\n\u001b[1;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\openai\\_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\openai\\_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1045\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1046\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\openai\\_base_client.py:1095\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\openai\\_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1045\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1046\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\openai\\_base_client.py:1095\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mi:\\AI_Project\\chatbot_agent\\Langgraph-Tutorial\\.venv\\lib\\site-packages\\openai\\_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1070\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 150 per 86400s exceeded for UserByModelByDay. Please wait 70911 seconds before retrying.', 'details': 'Rate limit of 150 per 86400s exceeded for UserByModelByDay. Please wait 70911 seconds before retrying.'}}"
     ]
    }
   ],
   "source": [
    "initial_stateee = AgentState(query=\"I want one stepper ui by two step, in step one exist input and checkbox fot name and sex of user and in step two there are many input for address ,age and phone number\")\n",
    "\n",
    "graph.invoke(initial_stateee)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
